{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Start by importing the bq_helper module and calling on the specific active_project and dataset_name for the BigQuery dataset.\nimport bq_helper\nfrom bq_helper import BigQueryHelper\n# https://www.kaggle.com/sohier/introduction-to-the-bq-helper-package\n\npatentsview = bq_helper.BigQueryHelper(active_project=\"patents-public-data\",\n                                   dataset_name=\"patentsview\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e1b552295be94db7a4dbaec24ad390ae99781cdc"
      },
      "cell_type": "code",
      "source": "# View table names under the patentsview data table\nbq_assistant = BigQueryHelper(\"patents-public-data\", \"patentsview\")\nbq_assistant.list_tables()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "09cca84d9febd423acc4cddef3d06be17f808e3e"
      },
      "cell_type": "code",
      "source": "# View the first three rows of the patent data table\nbq_assistant.head(\"patent\", num_rows=3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3899f766a4d032124220288c8225aa9d5c5a8b17"
      },
      "cell_type": "code",
      "source": "# View information on all columns in the patent data table\nbq_assistant.table_schema(\"patent\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c107cf7e6f83a04b1a796ef3346d0de9c6fec212"
      },
      "cell_type": "code",
      "source": "# View the first ten rows of the ipcr data table\nbq_assistant.head(\"ipcr\", num_rows=10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "aef22c4e4f4d2c7b918ebeeb2c3d88fd81ae91cd"
      },
      "cell_type": "code",
      "source": "# View information on all columns in the ipcr data table\nbq_assistant.table_schema(\"ipcr\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4f3c904b16428b856fc9b86a87332592f9e44bd4"
      },
      "cell_type": "markdown",
      "source": "##What is the IPC?\n\nhttps://en.wikipedia.org/wiki/International_Patent_Classification"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "07966e3a3e40ae93d0fbe82b71481134e08f950d"
      },
      "cell_type": "code",
      "source": "query4 = \"\"\"\nSELECT DISTINCT\n  a.id, a.abstract, b.section\nFROM\n  `patents-public-data.patentsview.patent` a\nINNER JOIN\n  `patents-public-data.patentsview.ipcr` b\nON\n  a.id = b.patent_id\nWHERE\n  a.type = 'utility'\nLIMIT\n  2000;\n        \"\"\"\n\nbq_assistant.estimate_query_size(query4)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9b5dfa90d910c3d21ebecad24ab340c96b6b67ac"
      },
      "cell_type": "code",
      "source": "response4 = patentsview.query_to_pandas(query4)\nresponse4.head(10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4e80f6445ecc70121d3f59abf70c402d1fd535d8"
      },
      "cell_type": "code",
      "source": "response4.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "99c12240c91ce63deb892deaed0b4e0fc409b4a7"
      },
      "cell_type": "code",
      "source": "labels = response4[\"section\"]\nfeatures = response4[\"abstract\"]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2493a3bd30f4e23f7e96de214fa79ffdbb00409e"
      },
      "cell_type": "code",
      "source": "Section_dict = {}\nsections = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\nfor section in sections:\n    Section_dict[section] = labels.str.count(section).sum()\n\nSection_dict",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4c07c90297fc01b70a25d70874bccaca1948326f"
      },
      "cell_type": "code",
      "source": "sum(Section_dict.values())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3e476ce3e024b108c28646c64055bd9fc86ff6ba"
      },
      "cell_type": "code",
      "source": "#plot distribution of sections\nimport matplotlib.pyplot as plt\nplt.bar(range(len(Section_dict)), list(Section_dict.values()), align='center')\nplt.xticks(range(len(Section_dict)), list(Section_dict.keys()))\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b2a3520803925172f8d9d3bba76bf35c7a13d986"
      },
      "cell_type": "code",
      "source": "#plot relative distribution of sections\nplt.bar(range(len(Section_dict)), np.array(list(Section_dict.values()))/len(labels), align='center')\nplt.xticks(range(len(Section_dict)), list(Section_dict.keys()))\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2334185e6458e0af009553fbce53fdf59add4d0c"
      },
      "cell_type": "code",
      "source": "def to_multilabel_encode(labels, features, num_codes):\n    \"\"\"Input:\n        features: list of the features\n        labels: list of the labels associated with each feature in features, \n                wherein the labels are single uppercase letters from A to ...(defined by num_codes)\n        num_codes: int, maximum number of codes\n        Output:\n            tuple of two numpy arrays, wherein the first array contains the features\n            and the second array contains the corresponding features encoded in a \"multi\"-hot-encoding\n    \"\"\"\n    assert len(labels) == len(features)\n    assert num_codes > 0\n    assert type(labels) == type([])\n    assert type(features) == type([])\n    features_final = []\n    labels_final = []\n    label_vector = np.zeros(num_codes)\n    \n    for index, feature in enumerate(features):\n        if feature == None:\n            pass\n        else:\n            if index == 0:\n                try:\n                    label_vector[ord(labels[index]) - 65] = 1\n                except:\n                    pass\n            else:\n                if feature == features[index - 1]:\n                    try:\n                        label_vector[ord(labels[index]) - 65] = 1\n                    except:\n                        pass\n                else:\n                    labels_final.append(label_vector)\n                    features_final.append(features[index - 1])\n                    label_vector = np.zeros(num_codes)\n                    try:\n                        label_vector[ord(labels[index]) - 65] = 1\n                    except:\n                        pass\n\n    labels_final.append(label_vector)\n    features_final.append(features[-1])\n    \n    return (np.array(features_final), np.array(labels_final))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "eceea9a23817f94341269f4b62a73c686eb2ab03"
      },
      "cell_type": "code",
      "source": "features = response4[\"abstract\"].tolist()\nlabels = response4[\"section\"].tolist()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4f66ff032828145bdfa9f383d643a99e5b84439f"
      },
      "cell_type": "code",
      "source": "num_codes = 8\nfeatures, labels = to_multilabel_encode(labels, features, num_codes)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b417c6d8a78a6794de28f701a235cec1887fc2cc"
      },
      "cell_type": "code",
      "source": "print(features)\nprint(labels)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b6e2004bf6d66e89ae5f3592dd4199b2daaaa986"
      },
      "cell_type": "code",
      "source": "from keras.models import Model, Input\nfrom keras.layers import Dense, Embedding, GlobalMaxPooling1D\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.optimizers import Adam",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f6a43923d2fecb33fb595355afa173e9461f9eba"
      },
      "cell_type": "code",
      "source": "max_features = 20000  # number of words we want to keep\nmaxlen = 500  # max length of the abstract in the model\nbatch_size = 64  # batch size for the model\nembedding_dims = 20  # dimension of the hidden variable, i.e. the embedding dimension",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a5885d78d47b21bfc1cf1fe88ed6d7e24a51624c"
      },
      "cell_type": "code",
      "source": "X_train = features[0:len(features)//2]\nX_test = features[len(features)//2:]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "24bd4dae034bff2326415d3e97903cb09cf671dc"
      },
      "cell_type": "code",
      "source": "#continue here",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f53f2df2d68d78f78a11cbc4deadc5d7b66173bb"
      },
      "cell_type": "code",
      "source": "X_test.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "c4a4be875ba8bcfb59a19b24f13223bfdd10331f"
      },
      "cell_type": "code",
      "source": "min_length = 1\nfor element in enumerate(X_train):\n    try:\n        if len(element) < min_length:\n            print(element)\n    except:\n        print(element)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "1ab235842c4d31c423e5e4ea189aff2c93bfb338"
      },
      "cell_type": "code",
      "source": "tok = Tokenizer(num_words = max_features)\ntok.fit_on_texts(X_train.tolist() + X_test.tolist())\nx_train = tok.texts_to_sequences(X_train)\nx_test = tok.texts_to_sequences(X_test)\nprint(len(x_train), 'train sequences')\nprint(len(x_test), 'test sequences')\nprint('Average train sequence length: {}'.format(np.mean(list(map(len, x_train)), dtype=int)))\nprint('Average test sequence length: {}'.format(np.mean(list(map(len, x_test)), dtype=int)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3fefe9f5099123343baaca92db8249cd141ceaee"
      },
      "cell_type": "code",
      "source": "nn = Sequential()\nnn.add(Dense(64, activation=\"relu\", input_shape=(10000,)))\nnn.add(Dense(64, activation=\"relu\", input_shape=(10000,)))\nnn.add(Dense(num_codes, activation=\"sigmoid\"))\n\nnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "07eee798c3104f9a2e09afcd8ec8748a9f0e4e9e"
      },
      "cell_type": "code",
      "source": "#https://www.depends-on-the-definition.com/guide-to-multi-label-classification-with-neural-networks/\n#https://www.depends-on-the-definition.com/classify-toxic-comments-on-wikipedia/",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}